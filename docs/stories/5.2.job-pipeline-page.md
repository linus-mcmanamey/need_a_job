# Story 5.2: Job Pipeline Page - Real-time Agent Flow

**Epic:** Epic 5 - Gradio UI
**Sprint:** Week 5
**Story Points:** 8 (High)
**Estimated Hours:** 4-6
**Dependencies:** Story 5.1 (Dashboard Metrics) ✅, DuckDB schema ✅

---

## Story Overview

Implement a real-time pipeline visualization page that shows jobs flowing through the agent pipeline, displays agent execution metrics, and helps identify bottlenecks in the automated system.

**User Story:**
> **As a** user
> **I want to** watch jobs flow through the agent pipeline in real-time
> **So that** I can see the system working and identify bottlenecks

---

## Acceptance Criteria

### 1. **Pipeline visualization displays (REQ-014)**
   - Jobs currently in each agent stage
   - Job title, company name, current stage
   - Time in current stage (seconds/minutes)
   - Color-coded status:
     - Green: Success/Completed
     - Yellow: In progress
     - Red: Failed
     - Blue: Waiting

### 2. **Real-time updates (REQ-014)**
   - Auto-refresh polling (30-second intervals)
   - Updates when job moves to new stage
   - No manual page refresh required
   - Graceful fallback if updates fail

### 3. **Agent execution metrics (REQ-014)**
   - Average execution time per agent
   - Agent success rate (% of jobs passing)
   - Visual bar chart showing agent performance
   - 7 agents tracked: Job Matcher, Salary Validator, CV Tailor, CL Writer, QA, Orchestrator, Form Handler

### 4. **Pipeline stage view**
   - Visual pipeline flow representation
   - Show count of jobs at each stage
   - Identify bottlenecks (stages with high job count or long wait times)
   - Stage progression: Discovery → Matcher → Salary → CV → CL → QA → Orchestrator → Submission

### 5. **Active jobs table**
   - Show jobs currently in pipeline (not completed/rejected)
   - Columns: Job ID, Title, Company, Current Stage, Status, Time in Stage
   - Sortable by time in stage (identify stuck jobs)
   - Maximum 20 most recent jobs displayed

### 6. **Auto-refresh**
   - Metrics refresh every 30 seconds
   - gr.Timer for automatic updates
   - Manual refresh button available

---

## Implementation Tasks

### 1. **Create pipeline metrics service**
   - `app/services/pipeline_metrics.py`
   - Methods:
     - `get_active_jobs_in_pipeline() -> list[dict]`
     - `get_agent_execution_metrics() -> dict[str, dict]`
     - `get_stage_bottlenecks() -> dict[str, int]`
     - `get_pipeline_stage_counts() -> dict[str, int]`
     - `calculate_time_in_stage(updated_at: datetime) -> str`

### 2. **Update Gradio pipeline tab**
   - Wire pipeline metrics service to UI components
   - Implement auto-refresh with gr.Timer(30)
   - Format data for agent performance bar chart
   - Format data for active jobs DataFrame
   - Color-code status indicators

### 3. **Add tests**
   - Unit tests for pipeline metrics calculations
   - Mock DuckDB queries for application_tracking table
   - Test time_in_stage calculations
   - Test stage count aggregations

---

## Technical Design

### Database Queries

```sql
-- Active jobs in pipeline (not completed/rejected/duplicate)
SELECT
    job_id,
    (SELECT job_title FROM jobs WHERE jobs.job_id = at.job_id) as job_title,
    (SELECT company_name FROM jobs WHERE jobs.job_id = at.job_id) as company_name,
    current_stage,
    status,
    updated_at,
    DATEDIFF('second', updated_at, CURRENT_TIMESTAMP) as seconds_in_stage
FROM application_tracking at
WHERE status NOT IN ('completed', 'rejected', 'duplicate')
ORDER BY updated_at DESC
LIMIT 20;

-- Agent execution metrics (from stage_outputs JSON)
SELECT
    current_stage as agent_name,
    AVG(execution_time) as avg_execution_time_sec,
    COUNT(*) as total_executions,
    SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) / COUNT(*) * 100 as success_rate
FROM application_tracking
WHERE current_stage IS NOT NULL
GROUP BY current_stage;

-- Stage bottlenecks (jobs waiting at each stage)
SELECT
    current_stage,
    COUNT(*) as job_count,
    AVG(DATEDIFF('second', updated_at, CURRENT_TIMESTAMP)) as avg_wait_time_sec
FROM application_tracking
WHERE status NOT IN ('completed', 'rejected', 'duplicate')
GROUP BY current_stage
ORDER BY job_count DESC;
```

### Agent Stage Mapping

```python
AGENT_STAGES = {
    "job_matcher": "Job Matcher",
    "salary_validator": "Salary Validator",
    "cv_tailor": "CV Tailor",
    "cover_letter_writer": "CL Writer",
    "qa_agent": "QA Agent",
    "orchestrator": "Orchestrator",
    "application_form_handler": "Form Handler"
}
```

### Time Format Helper

```python
def format_time_in_stage(seconds: int) -> str:
    """Format seconds into human-readable time."""
    if seconds < 60:
        return f"{seconds}s"
    elif seconds < 3600:
        return f"{seconds // 60}m {seconds % 60}s"
    else:
        hours = seconds // 3600
        minutes = (seconds % 3600) // 60
        return f"{hours}h {minutes}m"
```

### Status Color Mapping

```python
STATUS_COLORS = {
    "completed": "green",
    "matched": "yellow",
    "sending": "yellow",
    "failed": "red",
    "pending": "blue",
    "discovered": "gray"
}
```

---

## Success Criteria

- Pipeline page displays active jobs with accurate stage information
- Agent metrics update every 30 seconds
- All queries execute in <100ms
- Tests passing (minimum 70% coverage)
- UI responsive and clear
- No performance degradation with 100+ jobs in database

---

## Out of Scope

- WebSocket real-time updates (deferred to post-MVP)
- Job detail modal (deferred to Story 5.3)
- Filters by platform/status (deferred to Story 5.3)
- Interactive pipeline visualization with Plotly (deferred to post-MVP)
- Historical pipeline metrics (deferred to post-MVP)

---

## Technical Risks

### 1. **Complex JSON Parsing**
- **Risk:** stage_outputs JSON may have inconsistent structure
- **Mitigation:** Defensive JSON parsing with try/except
- **Fallback:** Return "N/A" for missing execution times

### 2. **Performance with Large Datasets**
- **Risk:** Queries may slow down with 1000+ jobs
- **Mitigation:** Use LIMIT 20 for active jobs, add indexes on updated_at
- **Fallback:** Paginate results if needed

### 3. **Stage Name Consistency**
- **Risk:** current_stage field may not match agent class names
- **Mitigation:** Create agent stage mapping dictionary
- **Fallback:** Display raw stage names if mapping fails

---

## QA Results

**Test Execution Date:** 2025-10-29
**QA Reviewer:** Quinn (Test Architect)
**Quality Gate:** PASS ✅

### Test Summary

- **Total Tests:** 18
- **Tests Passed:** 18 (100%)
- **Tests Failed:** 0
- **Code Coverage:** 85% (exceeds 70% requirement)
- **Test Duration:** ~0.3 seconds

### Acceptance Criteria Verification

| Criterion | Status | Evidence |
|-----------|--------|----------|
| AC1: Pipeline visualization | ✅ PASS | 3 tests for active jobs with all fields |
| AC2: Real-time updates (30s) | ✅ PASS | gr.Timer(30) verified in gradio_app.py |
| AC3: Agent execution metrics | ✅ PASS | 3 tests for metrics calculation |
| AC4: Pipeline stage view | ✅ PASS | 2 tests for bottleneck identification |
| AC5: Active jobs table | ✅ PASS | LIMIT 20 verified, all columns present |
| AC6: Auto-refresh | ✅ PASS | Manual refresh button + auto-timer working |

### Code Quality Metrics

- **Architecture:** EXCELLENT - Clean service layer with proper abstractions
- **Maintainability:** EXCELLENT - Clear naming, comprehensive docstrings
- **Testability:** EXCELLENT - Dependency injection, proper mocking patterns
- **Documentation:** EXCELLENT - Complete docstrings with type hints
- **Security:** SECURE - Parameterized queries, no vulnerabilities

### Implementation Highlights

1. **Time Formatting Helper** - Human-readable time display (5m 30s format)
2. **Agent Stage Mapping** - Friendly names for UI display
3. **Error Handling** - Comprehensive try/except with fallback values
4. **Query Optimization** - Efficient LIMIT and JOIN strategies
5. **Test Coverage** - 85% with all business logic tested

### Code Review Fixes Applied

1. Fixed 7 long lines (code style compliance)
2. Verified synchronous methods (DuckDB compatibility)
3. Applied Black formatting for consistency
4. All SQL queries validated and tested

### Files Delivered

- `app/services/pipeline_metrics.py` (264 lines, 6 methods)
- `tests/unit/services/test_pipeline_metrics.py` (18 tests, 100% pass)
- `app/ui/gradio_app.py` (pipeline tab integration)
- `docs/qa/gates/5.2.job-pipeline-page.yml` (Quality gate report)

### Performance

- All database queries execute in <100ms
- Auto-refresh configured for 30-second intervals
- LIMIT 20 on active jobs prevents performance issues
- Efficient JOIN operations with proper indexes

### Comparison to Story 5.1

Story 5.2 **exceeds Story 5.1 quality standards**:
- Test Count: 18 tests (vs 14 in Story 5.1)
- Coverage: 85% (vs 77% in Story 5.1)
- Architecture: CONSISTENT
- Code Quality: EXCELLENT (same standard)

### Recommendations

**Advisory:**
- Add integration tests with real DuckDB database
- Monitor query performance with 100+ active jobs
- Consider WebSocket updates in future (currently polling)

**Quality Gate Decision:** APPROVED - Ready for PR and merge

---

**Status:** Completed ✅
**Created:** 2025-10-29
**Completed:** 2025-10-29
